%%%%%%%%%%%%%%%%%%%Sif%%%% file typeinst.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is the LaTeX source for the instructions to authors using
% the LaTeX document class 'llncs.cls' for contributions to
% the Lecture Notes in Computer Sciences series.
% http://www.springer.com/lncs       Springer Heidelberg 2006/05/04
%
% It may be used as a template for your own input - copy it
% to a new file with a new name and use it as the basis
% for your article.
%
% NB: the document class 'llncs' has its own and detailed documentation, see
% ftp://ftp.springer.de/data/pubftp/pub/tex/latex/llncs/latex2e/llncsdoc.pdf
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[runningheads,orivec,a4paper]{llncs}

\usepackage{bbding}
\usepackage{xspace}
\usepackage{wrapfig}
\usepackage{threeparttable}
\usepackage{amssymb,amsmath}
\setcounter{tocdepth}{3}
%\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{amsmath}
\usepackage{bbm}
%\usepackage[ruled,vlined]{algorithm2e}
\usepackage[noend]{algpseudocode}
\usepackage{algorithmicx,algorithm}
\usepackage{url}
\usepackage{color}
%\usepackage{verbatim}
\usepackage{multicol}
\usepackage{lipsum}
\usepackage{xspace}
\newsavebox{\tablebox}
\usepackage{multirow}
%\usepackage{setspace}
%\usepackage{caption}
%\captionsetup[table]{font=small,skip=-4pt} 
%%\usepackage{enumitem}
\usepackage{paralist}
%\usepackage[hang,small,labelfont=,textfont=]{caption}
\usepackage[nodisplayskipstretch]{setspace}
\AtBeginDocument{%
  \addtolength\abovedisplayskip{-0.5\baselineskip}%
  \addtolength\belowdisplayskip{-0.5\baselineskip}%
%  \addtolength\abovedisplayshortskip{-0.5\baselineskip}%
%  \addtolength\belowdisplayshortskip{-0.5\baselineskip}%
}
%\setlength\abovetabcaptionskip{-5pt}
%\setstretch{1}
%\makeatletter
%\renewcommand\normalsize{%
%   \@setfontsize\normalsize\@xpt\@xiipt
%   \abovedisplayskip 1\p@ \@plus2\p@ \@minus5\p@
%   \abovedisplayshortskip \z@ \@plus3\p@
%   \belowdisplayshortskip 6\p@ \@plus3\p@ \@minus3\p@
%   \belowdisplayskip \abovedisplayskip
%   \let\@listi\@listI}
%\makeatother

\let\itemize\compactitem
\let\enditemize\endcompactitem
\let\enumerate\compactenum
\let\endenumerate\endcompactenum
\let\description\compactdesc
\let\enddescription\endcompactdesc
%\usepackage{etoolbox}
%\pltopsep=0pt%\medskipamount
%\plitemsep=0pt
%\plparsep=0pt
%
%%=============added by Rj to reduce space
%\setlength{\parskip}{2pt}
\newcommand{\marginremark}[2]{\annotatedmarginremark{\clubsuit}{$\clubsuit$}{#1}{#2}}
\newcommand{\rjnote}{\color{blue}}
\newcommand{\ccnote}[1]{\marginremark{CH}{#1}}
%\newcommand{\rjnote}[1]{\marginremark{RJ}{#1}}
\def\mathbi#1{\textbf{\em #1}}
% \newcommand{\comment}[1]{}
  \newcommand{\sig}[1]{\textsf{{\small #1}}}
  \newcommand{\nn}{\mathbb{N}}
\newcommand{\bool}{\mathbb{B}}
%\theoremstyle{definition}
%\newtheorem{proposition}{Proposition}
\newtheorem{defi}{Definition}

\begin{document}

%\mainmatter  % start of an individual contribution

% first the title is needed
\title{Contention-aware Task Mapping and Scheduling with Hybrid Search for Heterogeneous NoC-based MPSoCs}

% a short form should be given in case it is too long for the running head
%\titlerunning{A hybrid algorithm for multi-objective mapping and scheduling optimization of MPSoCs}
%\authorrunning{Cheng, Bensalem, Yan, Ruess, Buckl, Knoll}
%% the name(s) of the author(s) follow(s) next
%%
%% NB: Chinese authors should write their first names(s) in front of
%% their surnames. This ensures that the names appear correctly in
%% the running heads and the author index.
%%
%\author{
%Chih-Hong Cheng\inst{1}\inst{2} \and Saddek Bensalem\inst{3} \and Rongjie
%Yan\inst{4} \\ Harald Ruess\inst{1} \and Christian Buckl\inst{1} \and Alois Knoll\inst{2}
%%\and
%%Christian Buckl\inst{5}
%%\and
%%Alois Knoll\inst{1}
%%\and
%%Harald Ruess\inst{4}
%} \institute{
%fortiss GmbH, M\"{u}nchen, Germany   \\
%\and
%Department of Informatics, Technische Universit√§t M\"{u}nchen, M\"{u}nchen, Germany   \\
%\and
%Verimag Laboratory, Grenoble, France\\
%\and State Key Laboratory of Computer Science, ISCAS, Beijing, China\\
%% \url{http://www6.in.tum.de/~chengch/vissbip}
%}

\maketitle
\begin{abstract}


\end{abstract}


%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
%\begin{CCSXML}
%<ccs2012>
% <concept>
%  <concept_id>10010520.10010553.10010562</concept_id>
%  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
%  <concept_significance>500</concept_significance>
% </concept>
% <concept>
%  <concept_id>10010520.10010575.10010755</concept_id>
%  <concept_desc>Computer systems organization~Redundancy</concept_desc>
%  <concept_significance>300</concept_significance>
% </concept>
% <concept>
%  <concept_id>10010520.10010553.10010554</concept_id>
%  <concept_desc>Computer systems organization~Robotics</concept_desc>
%  <concept_significance>100</concept_significance>
% </concept>
% <concept>
%  <concept_id>10003033.10003083.10003095</concept_id>
%  <concept_desc>Networks~Network reliability</concept_desc>
%  <concept_significance>100</concept_significance>
% </concept>
%</ccs2012>  
%\end{CCSXML}
%
%\ccsdesc[500]{Computer systems organization~Embedded systems}
%\ccsdesc[300]{Computer systems organization~Redundancy}
%\ccsdesc{Computer systems organization~Robotics}
%\ccsdesc[100]{Networks~Network reliability}


%
% End generated code
%

%
%  Use this command to print the description
%


% We no longer use \terms command
%\terms{Theory}
%\vspace*{-10pt}
%\keywords{task allocation and scheduling; multi-objective optimization; local search; NSGAII framework}
\section{Introduction}\label{se:intro}

The scalable communication architecture makes network-on-chip (NoC) a prevailing solution for the next generation multiprocessor system-on-chips (MPSoCs). 
In the NoC paradigm, an important issue is how to map and schedule tasks of an application to processing elements (PEs), such that the system performance is maximized, while minimizing total energy consumption~\cite{deb2016energy,agyeman2016performance}. Within this architecture, communication is the main concern in the optimization process. To reduce communication consumption, tightly coupled tasks will be closely allocated, which may increase the possibility of communication \textit{contention} for frequent data transfer over same paths.%, or temperature hotspots for keeping some PEs continuously running.  
The increase in contention may incur long latency from network congestion thus leading to high energy consumption and poor system performance. %And the thermal hotspots may incur system reliablility problems. 
Reducing contention requires detailed scheduling and long latency in communication.
Therefore, it is a great challenge for NoC designers to tackle the issues on performance and energy consumption. 

With contention awareness in the design of NoCs, performance and energy consumption optimization need to consider how to map tasks to available PEs and how to schedule tasks on same PEs to avoid contention. 
In this paper, system performance is evaluated by \textit{makespan}, i.e., the scheduling length of the system. And energy consumption encompasses both computation and communication cost. Traditional works mainly focus on communication consumption with respect to the distance and the amount of data between various PEs, and the cost of computation is simplified as the sum of task execution cost on the allocated PEs. Therefore, the design optimization can be reduced to mapping optimization. However, various data transmission activities may require same resources and cause contention, which can lead to the big gap between ideal predication and real performance. 

To optimize performance and energy consumption with the consideration of potential contentions in communication, we construct formulations for mapping and scheduling constraints and objectives to be optimized. Meanwhile, we integrate a problem-specific local search into a  multi-objective evolutionary-based algorithm.  The main contributions of the paper are as follows. First, to reduce spacial contention in mapping, we encode the probability of contention in terms of overlapped paths, and formulate the distribution of contention probability as an objective that can be minimized. Second, to avoid temporal contention in data transmission, we construct the corresponding constraints in scheduling behavior. Third, the energy model encodes the power consumption on links and routers, as well as different modes of PEs. Finally, we construct a hybrid search algorithm, by integrating a local search into a generic algorithm. The algorithm is capable of dealing with large scale applications in approximating better Parent fronts. 
While various design choices exist for NoCs, in this paper, we limit our consideration to 2D mesh networks. 
However, our idea is applicable to other network topologies such as torus and 3D networks.

The rest of the paper is as follows. Section \ref{se:related} discusses related work in the domain static mapping and scheduling. Section \ref{se:concepts} introduces the task model and architecture model. Section \ref{se:model} provides the formulation of the problem. Section \ref{se:alg} presents the details of the algorithm. Experimental results are presented in Section \ref{se:exp}. Section \ref{se:con} concludes the paper.

\section{Related work}\label{se:related}

For embedded systems, energy efficiency is one of critical design issues. Consequently, communication energy minimization is the main concern for the mapping problem of NoCs~\cite{hu2005}. The corresponding cost uses directly or indirectly the average number of packet hops, with bandwidth or latency constraints~\cite{murali2004bandwidth,bhardwaj2009energy,chou2008contention}. 
%Additional to communication cost minimization, thermal balance can also be achieved in mapping optimization~\cite{hung2004thermal}. 
To have a global view of the entire NoC, task mapping and scheduling with the consideration of communication latency is another important problem for the design of NoCs~\cite{yang2014effective,yang2016application}. 
For contention-aware works, considering it in mapping without time information is an over-approximation of contentions~\cite{chou2008contention}. Though the work in \cite{yang2016application} considers contention in scheduling, it introduces latency to avoid contention and mainly focuses on makespan minimization. He et al. estimate traffic congestions by using heuristics~\cite{he2012unism}. Han et al. consider contention and energy-aware in mapping and scheduling, with pre-defined priorities for tasks and data transmissions~\cite{han2015contention}. 
To evaluate performance globally, we introduce contention reduction in both mapping and scheduling, and both performance and energy consumption can be optimized at the same time. 
%Meanwhile, we use overlapped area of two paths to quantify the probability of contention, which allows us to trade off between contentoin minimization and the capacability limitation of PEs.
 
Various algorithms exist for mapping optimization, such as tabu search~\cite{tino2011multi}, branch-and-bound~\cite{hu2003energy}, binary particle swarm optimization~\cite{lei2010energy}, and diagonal map~\cite{agrawal2010efficient}. Similar to the solutions for MPSoCs, genetic algorithms~\cite{nedjah2014application}, simulated annealing algorithm~\cite{chai2014list}, mixed integer linear programming (MILP)~\cite{yang2016application} have also used to solve the mapping and scheduling problems. 
An ILP formulation has been proposed for contention aware application mapping in tile based NoC to reduce inter-tile network contention\cite{chou2008contention}. 
%To minimize average communication delay and satisfy bandwidth constraints, Murali and De Micheli use minimum path routing in mapping optimization~\cite{murali2004bandwidth}. 
Huang et al. propose a simulated annealing algorithm with timing adjustment heuristic is proposed to minimize energy consumption \cite{huang2011energy}. 
%In the work of \cite{zang2015energy}, a genetic algorithm is applied to minimize both energy and hotspot temperature. 
These works only consider mapping issues for NoCs. 
The work in \cite{bolanos2013uml} employs population based incremental learning algorithm for mapping and scheduling optimiztation. He et al. introduce a unified model in mixed integer linear programming, for task mapping and scheduling~\cite{he2012unism}. 
%A partitioned earliest deadline first strategy is applied in an allocation algorithm for maximizing resource untilzation while minimizing average end-to-end worst case response time~\cite{ali2013critical}. 
An ILP formulation encoding fine-grain communication optimization is proposed in \cite{yang2016application}. And a heuristic algorithm is designed for application mapping and scheduling. To optimize the objectives in our constraint formulation, we put forward a hybrid search algorithm for both performance and energy optimization.
 Therefore, from the aspect of our formulation and the algorithm, the techniques discussed in the paper are different from existing works.


\section{Preliminaries}\label{se:concepts}
We consider applications represented using task graphs (TGs). A task graph is a directed acyclic graph (DAG).
\begin{defi}[Task Graph]
A task graph is a directed acyclic graph (DAG) with $G=\langle T,E\rangle$, where $T$ is a finite set of tasks, with $\delta: T\rightarrow \nn$ to indicate the amount of work to be dealt with on each task, and $E\subseteq T\times T$ is a set of precedence relations with $c: E\rightarrow \nn$ to indicate the amount of data transferred between each pair of tasks.
\end{defi} 
Each vertex may have a relative deadline, specifying the latest tolerable finishing time w.r.t. the start time of the first task in a period. %And a latest response time may also exist between various tasks. 
The model shown in Figure~\ref{fig:taskgraph}(a) is a task graph with 4 tasks and 5 dependency relations.  
\begin{figure}
\centering
 \includegraphics[width=0.85\columnwidth]{figures/running_example}% \vspace{-4.5mm}
  \caption{A running example.}
 \label{fig:taskgraph}
% \vspace{-3mm}
 \end{figure}
 
The target hardware is a 2D mesh NoC-based heterogeneous MPSoCs, as illustrated in Figure \ref{fig:taskgraph}(b). Each PE in the model is connected to a \textit{router}. And routers are connected with each other through bidirectional \textit{links}. Data transmission through the NoC is in the form of packets. If two consequential tasks are mapped to the same PE, data can be directly read without routing. Within this topology, the location of each PE 
can be determined by a pair of coordinates $(x_i,y_i)$. And the distance between any two PEs $p_i$ and $p_j$ is the Manhattan distance:
\begin{equation}
D_{ij}=abs(x_i-x_j)+abs(y_i-y_j)
\end{equation}
%XY-routing is assumed in this paper. 
Figure~\ref{fig:taskgraph}(b) shows an  example with 3$\times$3 nodes of two different types of processors, where the speed of processors with red cycles is two times faster than others. The communication is assumed to have cost 1 per unit payload per link.

We present two kinds of mappings for the model in Figure~\ref{fig:taskgraph}(a), where one utilizes faster processors and the other minimizes communication paths. With the mapping in Figure~\ref{fig:taskgraph}(b), the cost of computation is 55, and the cost of communication is 66, if we only consider the cost in links, and ignore the latency caused by contention during communication. For the case in Figure~\ref{fig:taskgraph}(c), the cost of computation is 70, and the cost of communication is 53. The first mapping have a contention between communications from $p_{00}$ to $p_{11}$ and from $p_{00}$ to $p_{12}$. However, the caused delay is only 1. Therefore, it is hard to choose without detailed performance and energy consumption information. 


\input{noc}
%\vspace{-5pt}

\section{The hybrid search algorithm}\label{se:alg}
As a result of the complexity of the multi-objective optimization and the enormity of searching exploration, some efficient strategies should be proposed to differentiate non-dominated solutions and enhance the selection pressure towards the pareto front. Accordingly, we have integrated a pareto local search method into the NSGAII framework together with objective-related heuristic extensions, aiming to tackle the mapping and scheduling on NoC paradigm. This approach consists of three stages of optimization based on the characteristic of the model mentioned above. The first stage is a task-grouping process, which aims to cluster the tasks with more dependence into one core. It is obvious that if more dependent tasks are gathered in the same core, less communication will occur, without other factors considered in this stage. Then, due to the heterogeneous architecture and communication  constraints, a core-tile mapping stage is needed to optimize the makespan and average contention probability. An inadaptable mapping will cause more congestion or remote transmission distance. At last, we are looking for a better sequence scheduling in each tile so as to minimize the makespan and satisfy the response time requirement between certain tasks. It should be noted that these three stages are initialized in a heuristic way in order, but are evolved in the evolution process as a whole. The optimization of each stage can be regarded as a multi-objective problem, so the incorporation of these three difficult problems make the mapping and scheduling more intractable. Also, three realistic objectives are considered, which increases the difficulty of this issue to a great extent. Detailed information about the algorithm is discussed in the following subsections.
\subsection{Encoding}
Before introducing the evolutionary algorithm, the representation of chromosome, which indicates the form of solution to the problem, is given. As is discussed in section 3, the location of each PE can be determined by a pair of coordinates $(x_i,y_i)$ within 2D mesh topology, which is troublesome for genetic operators. Each operative tile $p_k$ in the NoC has an associated gene which encodes the identifier of the core mapped in the tile. Thus, for a $n*m$ Noc, the chromosome encoding for the mapping and scheduling problem is shown in Fig.\ref{fig:encoding}. Every chromosome contains a set of mapped tasks, and the scheduled execution sequence for the allocated processors, which varies from conventional encoding for mapping optimization. Therefore, we need extra pointers to separate the genes for various processors. Moreover, three tips should be considered.
\begin{enumerate}[(1)]
\item $p_k \in P'$ is guaranteed, which means only the occupied processors are taken into consideration in the chromosome. 
\item $p_k$ can be translated into the location of 2-dimension coordinates $(x_i,y_i)$ in such a way: $x_i=k/m, y_i=k$ \textit{mod} $m$.
\item The index of $p_k$ may not be continuous but should be in ascending order for the reason of idle tiles. As is shown in Fig.\ref{fig:encoding}, $p_2$ does not appear because no tasks are assigned on tile $(0,2)$. However, if there are tasks migrating to tile $(0,2)$ during evolution process, $p_2$ should be added into the position between $p_1$ and $p_3$ in order to map the tile $(0,2)$.
\end{enumerate} 
Next, we will discuss some primary components of the algorithm in detail and provide the whole framework.
\begin{figure}[h]
\centering%\vspace{-8pt}
 \includegraphics[width=0.2\columnwidth]{figures/encodingy.pdf}%\vspace{-10pt}
  \caption{Chromosome encoding}
 \label{fig:encoding}
 %\vspace{-5mm}
 \end{figure}
%\vspace{-5pt}
\subsection{Initialization}
The idea behind the proposed initialization is to blend some priori knowledge or heuristic information into the pure random construction adopted by general research, for the reason that the exploration space for three-objective is fairly wide. A diversified population could provide a greater chance to find the optimal, yet would result in slow convergence. While an intensified population could converge fast, yet would make the algorithm trap into local optimum. By this token, some candidate solutions would be generated randomly to cover a more comprehensive solution domain, while a few constructive solutions are also needed to store problem-heuristic information for a faster convergence. So given the three stages of optimization, the initialization process could be divided into two steps, and the scheduling optimization is mixed together with grouping and mapping to reduce the complexity of the method.

We adopt different strategies against various situation of the task graph. Most techniques deflect to the reduction of communication cost, as communication is the major concern in the optimization process. The first heuristic solution for grouping is generated by following steps, which takes makespan and communication into consideration. 
\begin{enumerate}[(1)]
\item If the task graph is disconnected, the number of groups we classify is equal to the amount of connected components, and each connected component is regarded as a group. In this way, no packets will be transmitted in the network.
\item Conversely, if there are no disconnected graphs in the task graph, a distribution of parallel tasks is recommended to be executed simultaneously. For each task $t$, in-degree $In(t)$ is calculated according to the dependency relation of tasks. For the task whose $In(t)$ is zero, it is pushed into the execution sequence, and if there are other tasks whose $In(t)$ is zero, they are pushed into the execution sequence and locked. Every time an unlocked task is popped and assigned to the current group. Then, the in-degrees of its successors decrease by 1. When no tasks are allowed to allocate, unlock one task in the execution sequence and divide it into a new group. Loop continues until all the tasks are assigned. The sequence of popped tasks also represents a scheduling plan to the problem, because every task is guaranteed to be executed after its dependent tasks.
\item It should be noted that too many parallel tasks will cause an exceeding number of groups comparing with limited PEs. Thus, some groups should be mapped into the same PE. The fulfilment is inspired by the fact that the processors with minor tasks will be idle for a long time, which is a waste of energy consumption. So, the groups are ranked in descending order by the computation time, and we try to merge the last two groups into a new one every time until the number of groups meets the quantitative requirement. The rule of combination follows an insertion-in-turn operator, meaning that the element selected to be inserted into the new group from one group is followed by the task from another, which keeps the sequence of tasks in the original group unchanged. For the tasks whose execution sequence are inadequate within the group, delay them until their dependent tasks having been performed.
\end{enumerate} 

The output of grouping stage is an input of mapping process, including a set of groups.

In order to accelerate the convergence of mapping, an easy implementing called Spiral algorithm is adopted as~\cite{mehran2007spiral} does. Different from the original task searching, a group searching is proposed to reduce communication cost ulteriorly. The placement of a group is searched in a spiral path from centre to the boundary of the network architecture. It tries to place the communicating groups close to each other, decreasing the transmission path between two PEs. Furthermore, the characteristic of spiral architecture makes communicating groups locate on different directions in order to lower the probability of potential contention. With the mapping rules above, the transmission cost between each group and the total cost of one group is calculated respectively. Afterwards, the most costly group is assigned to the center and next to it is the group with the highest transmission cost to communicate. Break ties randomly if there exist more than one feasible groups. 
The initial solution with heuristic information is hereby generated and other solutions are produced in a random mode to cover a wider searching space. In this way, we can obtain an initial population with a balance between the diversified population and the convergence.
Then the initial population will be divided into several sub-populations by the non-dominated sorting strategy in NSGAII, each of which is sorted according to the crowding distance to ensure a wider distribution.
\subsection{Genetic Process}
In this process, we propose an uniform crossover and a split (or merge) based mutation operator in the genetic procedure, to improve the feasibility and diversity of solutions. 

The crossover operator performs a random selection of two parents from the dynamic elitist population and the evolution population. Then each task in the offspring inherits the position in one of its parents randomly. So, the positions of every task in the parents are recorded. The uniform crossover can help avoid the case that a task is assigned to different processors.

The mutation operator focuses on the conversion of task mapping for the purpose that subsequent local search is applied based on the fixed mapping, which is easier to trap into the local optimum given a constant mapping. To be specific, each individual receives a mutation probability, neither too small nor too large. A small probability will cause a long time stagnation on evolution, while a large one will lead to an insufficient search for the existing structure. For mutation, an occupied probability $P_o$ is calculated as $P_o=|P'|/|P|$, and a split perturbation will be adapted on a probability of $P_o$, together with a merge perturbation executed on a probability of ($1-P_o$). In this way, it is possible to adjust the number of running processors dynamically according to the occupied status. More processors are likely to be allocated if tasks have gathered into a few processors, and the combination of processors with low utilization is preferred if the distribution of tasks is scattered. In a split operator, the most time-consuming processor is supposed to decompose into two light processors, each of which shares half of the computation load. The new generated processors are mapped into the first two available PEs in terms of the spiral rule. As for the merge operator, it is performed the same as initial procedure does except that the merge stage is conducted only once and the incorporative processor is mapped into the first available PE according to the spiral rule. 
\subsection{Pareto local search}
In the $\epsilon$-MOHA algorithm, we use a pareto local search (Alg\ref{alg3}) to enhance the intensive searching capacity. The procedure consists of a repair step for infeasible solutions, an insert-based
neighbourhood comparison and generation step.

A repair operator on the infeasible solutions is needed to spare the resource (Alg\ref{alg3}.line 2). The main idea of \textit{repair} operator is to repeatedly check the feasibility of executing tasks and ensure that each task begins to execute later than all its dependent tasks.

Another important factor in the Pareto local search procedure is the neighborhood structure. Given a candidate solution \textit{S} and two tasks $t$ and $t'$, if we only insert the position of the task $t$ into the head of task $t'$ and fix the positions of other tasks, we can obtain a neighbor solution of \textit{S}. We then use \textit{neighbor($S_t$)} to denote the set of neighbors of \textit{S} by inserting $t$ into other positions. In the main Pareto local search loop (Alg\ref{alg3}.line 3-10), the algorithm randomly selects a task $t$ of solution $S$ (Alg\ref{alg3}.line 4) and tries to find a solution that can $\epsilon$-dominate $S$ from its neighborhood space (Alg\ref{alg3}.line 5). Specifically, if \textit{neighbor($S_t$)} is better than \textit{S} based on Pareto optimal evaluation, it will replace \textit{S} for further exploitation and $iter$ is set to 1 to look for a better neighorhood than the current. Meanwhile, the elitist population $S_E$ is updated (Alg\ref{alg3}.line 6-8). Otherwise, another task will be selected and $iter$ will be increased by 1 (Alg\ref{alg3}.line 10). This process continues until $iter$ reaches the maximum limit.

\begin{algorithm}\scriptsize
\caption{Pareto-Localsearch($S$)}
\label{alg3}
\begin{algorithmic} [1]
\State Input: a starting solution $S$, the maximum allowed iterations $MaxIter$
\State Output: Elite solution set $S_E$
\State $iter=1$;
%\State $kmax=|T|$
\State repair($ S $);
\While {$iter\leq  MaxIter$}
\State $t$= Random-Task-selection($S$);
\State $ Nh(S_t) $ = Neighborhood$(S_t)$;
\If    {$ Nh(S_t) $ $\epsilon$-dominates $ S $}
\State $S$=$Nh(S_t)$; $S_E$=Update($S$);
\State $iter=1$;
%\State 
\Else
\State $iter=iter+1$;
\EndIf
\EndWhile
\State return $S$;
\end{algorithmic}
\end{algorithm}%\vspace*{-\baselineskip}
\subsection{Value-based Dominance}
The contention-aware task mapping and scheduling problem with three objectives has a huge solution domain, which is exhausive to solve and will produce a large amount of solutions. For a decision maker, too many candidate solutions are more likely to bring extra artificial workload. Consequently, a value-based dominance method is adopted to enlarge the dominating area of the non-dominated solutions so that some of them are more likely to be dominated by others. Among the value-based dominance category, $\epsilon$-dominance proposed by Laummans et al ~\cite{laumanns2002combining} has drawn greater attention and achieved a  superior performance. So, it is also integrated into our algorithm called $\epsilon$-MOHA. Given two solutions $x,y \in \Omega$ and $\epsilon >0$, $x$ is said to $\epsilon$-dominate $y$, iff $\forall i \in \{1,...m\}$, $(1-\epsilon)f_i(x) \leq f_i(y) $. For example, if $\epsilon$ is set to 0.1, and the makespan, total amount of energy cost, contention of solution $x=(100,200,0.9)$, another solution $y=(102,100,0.9)$. $x$ and $y$ are non-dominance solutions and will be determined by decision makers. As can be seen, the makespan of $y$ is slightly worse than $x$, but the energy cost is much better than $x$, leading to the preferred selection of solution $y$. Under the concept of $\epsilon$-dominance, only solution $y$ is recommended to decision makers, which reduces the Pareto set.

\section{Experimentation}\label{se:exp}
This section presents computational experiments to test the efficiency of our $\epsilon$-MOHA algorithm. The effectiveness of the model and the efficiency of the algorithm have been evaluated with realistic benchmarks, including an H264 decoder~\cite{IEICE14}, a TMNR procedure~\cite{cotton2011multi}, a Multi-Window Display (MWD) application~\cite{atienza2008},  a Livermore Loop and a Bufferfly ~\cite{kessler2009optimized}, and an MP3 decoder. %Ultrasound~\cite{wang2014case}. 
All the experiments are performed on a PC with intel 2.2 GHz processor and 8.0 GB memory. 
\subsection{Experimental setup}
The   constant   factors are  set to E1=240$\mu W$/MHz for the energy cost of per processor clock cycle.
E2=24$\mu W$/MHz for per hop cost for router ,  and E3=6.8$\mu W$/MHz for per packet transmission~\cite{yang2016application}.

\subsection{Random generated cases}

\subsubsection{Effectiveness for contention-aware optimization}
To evaluate the effectiveness of Constraint \ref{eq:linklap} and Objective \ref{eq:contention}, we set three groups of experiments: only consider Constraint \ref{eq:linklap} (CC), only consider Objective \ref{eq:contention} (OC), and consider the two (OCC). We compare performance, energy consumption, and the number of contentions in Table \ref{tab:contention}.   
\begin{table}[htp]\caption{Contention-aware strategy comparison\label{tab:contention}}
\begin{lrbox}{\tablebox}
\begin{tabular}{| l |ll|  lll | lll | lll |}\hline
\multirow{2}{*} {Case} &\multicolumn{2}{|c|}{Scale} & \multicolumn{3}{|c|}{CC} &\multicolumn{3}{|c|}{OC} & \multicolumn{3}{|c|}{OCC}\\\cline{2-12}
 & tasks& edges &makespan & energy & contention & makespan & energy & contention & makespan & energy & contention \\\hline
\end{tabular}
\end{lrbox}
\scalebox{0.8}{\usebox{\tablebox}}
\end{table}
%\begin{itemize}
%\item Compare energy and performance with/without contention minimization. 
%
%\item Calculate the cases with data transfer happens in the same durations over same links (real contention cases) with/without contention minimization.
%\end{itemize}
\subsubsection{Comparison with other algorithms} To show the efficiency of MOHA, we compare the performance with NSGAII. 
\subsection{Real benchmarks}

\section{Conclusion}\label{se:con}
\begin{small}
%\vspace{-6pt}
\bibliographystyle{abbrv}
\bibliography{ilp}
\end{small}

\end{document}
